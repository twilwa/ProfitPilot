

<!-- Living README Summary -->
## 🌳 Living Summary

This folder contains files related to a conversational AI sales agent. The main file, "main.py," provides a framework for building and running the agent. It imports the "Agent" class from the "agent.py" file, which represents the AI agent and handles generating responses based on given tasks. The "llama.py" file defines a class for text generation using a pre-trained language model. The "tools.py" file contains various tools and utilities for data processing, web scraping, and natural language processing. The "__init__.py" file is a script to run the "ProfitPilot" and "Agent" classes.


### `__init__.py`

📝 This file is a script to run the ProfitPilot and Agent classes.


### `agent.py`

📝 This file defines a class named "Agent" that represents an AI agent.
📦 The agent is designed to perform various tasks using a set of tools.
🔧 The tools include file reading and writing, CSV processing, website querying, email drafting, data scraping, and more.
💡 The agent can be configured to operate with or without human input in the loop.
📚 The agent uses a language model called LLama2 and OpenAI embeddings for natural language understanding.
🔍 The agent utilizes the FAISS library for vector indexing and retrieval.
🔀 The agent can handle exceptions and errors during setup and execution.
🏃 The agent can be invoked by calling its "run" method with a task as input.
📢 The agent can also be called directly as a function, which is a shorthand for invoking the "run" method.
🔒 The agent is designed to be extensible with additional external tools.


### `llama.py`

📝 This file defines a class called "LLama2" that is used for text generation using a pre-trained language model.
🔧 The class takes in various parameters such as the model ID, device, and maximum length of the generated text.
🔗 The class initializes the tokenizer and model using the specified model ID.
🔍 The "__call__" method generates text based on a given prompt using the model and tokenizer.
🔄 The "generate" method is a wrapper for "__call__" method, providing an alternative way to generate text.
⚠️ If there is an error during model or tokenizer loading or text generation, an exception is raised.
💻 The class can be instantiated with different configurations, such as enabling quantization.
📚 The class uses the Hugging Face Transformers library for model and tokenizer functionality.
🔒 The class ensures that the model is loaded on the available GPU if CUDA is available, otherwise on the CPU.
🔧 The class also supports quantization of the model using the "BitsAndBytesConfig" class if specified.


### `main.py`

📄 This file contains a class called "ProfitPilot" which is intended to act as a sales agent in a conversational AI system. 
🤖 The class has various attributes related to the AI's role, the company it represents, the conversation history, and more. 
📝 The class also has a "run" method that initializes an instance of the "Agent" class and runs a given task. 
💼 The purpose of this file is to provide a framework for building and running a conversational AI sales agent. 
🔧 The file imports the "Agent" class from the "profit.agent" module. 
📝 The "Agent" class is expected to handle the logic of generating responses based on the given task. 
💬 The file includes a system prompt and an example conversation history to guide the AI in generating appropriate responses. 
📝 The AI is intended to act as a salesperson named {salesperson_name} and generate responses based on the conversation stage and history. 
🖥️ The "run" method prints the response generated by the AI. 
🔍 The file can be used as a starting point for implementing a conversational AI sales agent.


### `tools.py`

📝 This file contains Python code for various tools and utilities related to data processing, web scraping, and natural language processing.
🔧 It imports libraries such as asyncio, os, pandas, and BeautifulSoup for different functionalities.
📂 It defines functions for processing CSV files, browsing web pages, and querying web pages for information.
🌐 It includes tools for web scraping using Playwright and searching with DuckDuckGo.
🔑 It also includes tools for interacting with Zapier's NLA (Natural Language Automation) API.
🧰 It defines a context manager for changing the current working directory.
📚 It imports and uses various modules and classes from the "langchain" package.
📄 It defines a tool for splitting text documents and a tool for running question-answering chains on web pages.
⚠️ Some parts of the code are still marked as TODO or have not been implemented yet.
🧩 It initializes instances of certain tools and assigns them to variables for later use.

<!-- Living README Summary -->